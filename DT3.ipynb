{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- d1_potassium_max_3.62\n- d1_potassium_max_3.86\n- d1_potassium_max_4.01\n- d1_potassium_max_4.06\n- d1_potassium_max_4.12\n- ...\nFeature names seen at fit time, yet now missing:\n- apache_4a_hospital_death_prob_0.99\n- d1_potassium_max_3.55\n- d1_potassium_max_3.67\n- d1_potassium_max_3.68\n- d1_potassium_max_3.78\n- ...\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32md:\\IBA\\ML\\Competition\\DT3.ipynb Cell 1\u001b[0m line \u001b[0;36m5\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/IBA/ML/Competition/DT3.ipynb#W0sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m dt_model \u001b[39m=\u001b[39m DecisionTreeClassifier(\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/IBA/ML/Competition/DT3.ipynb#W0sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m     criterion\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mgini\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/IBA/ML/Competition/DT3.ipynb#W0sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m     max_depth\u001b[39m=\u001b[39m\u001b[39m100\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/IBA/ML/Competition/DT3.ipynb#W0sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m     random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/IBA/ML/Competition/DT3.ipynb#W0sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m )\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/IBA/ML/Competition/DT3.ipynb#W0sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m dt_model\u001b[39m.\u001b[39mfit(X_top_15_encoded, y)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/IBA/ML/Competition/DT3.ipynb#W0sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m dt_predictions \u001b[39m=\u001b[39m dt_model\u001b[39m.\u001b[39;49mpredict_proba(test_data_top_15)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/IBA/ML/Competition/DT3.ipynb#W0sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m \u001b[39m# Create submission DataFrames\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/IBA/ML/Competition/DT3.ipynb#W0sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m submission_dt \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame({\u001b[39m\"\u001b[39m\u001b[39mRecordID\u001b[39m\u001b[39m\"\u001b[39m: test_data[\u001b[39m\"\u001b[39m\u001b[39mRecordID\u001b[39m\u001b[39m\"\u001b[39m], \u001b[39m\"\u001b[39m\u001b[39mhospital_death\u001b[39m\u001b[39m\"\u001b[39m: dt_predictions[:, \u001b[39m1\u001b[39m]})\n",
      "File \u001b[1;32mc:\\Users\\Wasi Khan\\anaconda3\\envs\\iml\\lib\\site-packages\\sklearn\\tree\\_classes.py:992\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.predict_proba\u001b[1;34m(self, X, check_input)\u001b[0m\n\u001b[0;32m    968\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Predict class probabilities of the input samples X.\u001b[39;00m\n\u001b[0;32m    969\u001b[0m \n\u001b[0;32m    970\u001b[0m \u001b[39mThe predicted class probability is the fraction of samples of the same\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    989\u001b[0m \u001b[39m    classes corresponds to that in the attribute :term:`classes_`.\u001b[39;00m\n\u001b[0;32m    990\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    991\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[1;32m--> 992\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_X_predict(X, check_input)\n\u001b[0;32m    993\u001b[0m proba \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtree_\u001b[39m.\u001b[39mpredict(X)\n\u001b[0;32m    995\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_outputs_ \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\Wasi Khan\\anaconda3\\envs\\iml\\lib\\site-packages\\sklearn\\tree\\_classes.py:460\u001b[0m, in \u001b[0;36mBaseDecisionTree._validate_X_predict\u001b[1;34m(self, X, check_input)\u001b[0m\n\u001b[0;32m    458\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    459\u001b[0m     force_all_finite \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m--> 460\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[0;32m    461\u001b[0m     X,\n\u001b[0;32m    462\u001b[0m     dtype\u001b[39m=\u001b[39;49mDTYPE,\n\u001b[0;32m    463\u001b[0m     accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    464\u001b[0m     reset\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    465\u001b[0m     force_all_finite\u001b[39m=\u001b[39;49mforce_all_finite,\n\u001b[0;32m    466\u001b[0m )\n\u001b[0;32m    467\u001b[0m \u001b[39mif\u001b[39;00m issparse(X) \u001b[39mand\u001b[39;00m (\n\u001b[0;32m    468\u001b[0m     X\u001b[39m.\u001b[39mindices\u001b[39m.\u001b[39mdtype \u001b[39m!=\u001b[39m np\u001b[39m.\u001b[39mintc \u001b[39mor\u001b[39;00m X\u001b[39m.\u001b[39mindptr\u001b[39m.\u001b[39mdtype \u001b[39m!=\u001b[39m np\u001b[39m.\u001b[39mintc\n\u001b[0;32m    469\u001b[0m ):\n\u001b[0;32m    470\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mNo support for np.int64 index based sparse matrices\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Wasi Khan\\anaconda3\\envs\\iml\\lib\\site-packages\\sklearn\\base.py:580\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    509\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_validate_data\u001b[39m(\n\u001b[0;32m    510\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    511\u001b[0m     X\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mno_validation\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    516\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_params,\n\u001b[0;32m    517\u001b[0m ):\n\u001b[0;32m    518\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Validate input data and set or check the `n_features_in_` attribute.\u001b[39;00m\n\u001b[0;32m    519\u001b[0m \n\u001b[0;32m    520\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    578\u001b[0m \u001b[39m        validated.\u001b[39;00m\n\u001b[0;32m    579\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 580\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_feature_names(X, reset\u001b[39m=\u001b[39;49mreset)\n\u001b[0;32m    582\u001b[0m     \u001b[39mif\u001b[39;00m y \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_tags()[\u001b[39m\"\u001b[39m\u001b[39mrequires_y\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[0;32m    583\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    584\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThis \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m estimator \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    585\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mrequires y to be passed, but the target y is None.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    586\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\Wasi Khan\\anaconda3\\envs\\iml\\lib\\site-packages\\sklearn\\base.py:507\u001b[0m, in \u001b[0;36mBaseEstimator._check_feature_names\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    502\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m missing_names \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m unexpected_names:\n\u001b[0;32m    503\u001b[0m     message \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\n\u001b[0;32m    504\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFeature names must be in the same order as they were in fit.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    505\u001b[0m     )\n\u001b[1;32m--> 507\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(message)\n",
      "\u001b[1;31mValueError\u001b[0m: The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- d1_potassium_max_3.62\n- d1_potassium_max_3.86\n- d1_potassium_max_4.01\n- d1_potassium_max_4.06\n- d1_potassium_max_4.12\n- ...\nFeature names seen at fit time, yet now missing:\n- apache_4a_hospital_death_prob_0.99\n- d1_potassium_max_3.55\n- d1_potassium_max_3.67\n- d1_potassium_max_3.68\n- d1_potassium_max_3.78\n- ...\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.impute import KNNImputer  # Import KNNImputer for missing value handling\n",
    "\n",
    "# Load training and test data\n",
    "train_data = pd.read_csv(\"D:/IBA/ML/Competition/train.csv\")  # Replace \"train.csv\" with your training file path\n",
    "test_data = pd.read_csv(\"D:/IBA/ML/Competition/test.csv\")    # Replace \"test.csv\" with your test file path\n",
    "\n",
    "# Data preprocessing (you may need to customize this based on your dataset)\n",
    "# For simplicity, we'll encode categorical features using LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "categorical_features = [\"ethnicity\", \"gender\", \"icu_admit_source\", \"icu_stay_type\", \"icu_type\", \"apache_3j_bodysystem\", \"apache_2_bodysystem\"]\n",
    "for feature in categorical_features:\n",
    "    train_data[feature] = label_encoder.fit_transform(train_data[feature])\n",
    "    test_data[feature] = label_encoder.transform(test_data[feature])\n",
    "\n",
    "# Split the training data into features and target variable\n",
    "X = train_data.drop(columns=[\"RecordID\", \"hospital_death\"])\n",
    "y = train_data[\"hospital_death\"]\n",
    "\n",
    "# KNN impute missing values in both training and test data\n",
    "knn_imputer = KNNImputer(n_neighbors=5)  # Set the number of neighbors\n",
    "X_imputed = knn_imputer.fit_transform(X)\n",
    "test_data_imputed = knn_imputer.transform(test_data.drop(columns=[\"RecordID\"]))\n",
    "\n",
    "# Feature selection using SelectKBest with 15 best features\n",
    "selector = SelectKBest(score_func=f_classif, k=15)\n",
    "X_top_15 = selector.fit_transform(X_imputed, y)\n",
    "\n",
    "# Get the indices of the selected features\n",
    "selected_feature_indices = selector.get_support(indices=True)\n",
    "\n",
    "# Get the names of the selected features\n",
    "selected_feature_names = train_data.columns[selected_feature_indices]\n",
    "\n",
    "# Apply one-hot encoding to the selected features\n",
    "X_top_15_encoded = pd.get_dummies(X[selected_feature_names], columns=selected_feature_names, drop_first=True)\n",
    "test_data_top_15 = pd.get_dummies(test_data[selected_feature_names], columns=selected_feature_names, drop_first=True)\n",
    "\n",
    "# Now you can proceed with fitting the model and making predictions\n",
    "dt_model = DecisionTreeClassifier(\n",
    "    criterion='gini',\n",
    "    max_depth=100,\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=1,\n",
    "    random_state=42\n",
    ")\n",
    "dt_model.fit(X_top_15_encoded, y)\n",
    "dt_predictions = dt_model.predict_proba(test_data_top_15)\n",
    "\n",
    "# Create submission DataFrames\n",
    "submission_dt = pd.DataFrame({\"RecordID\": test_data[\"RecordID\"], \"hospital_death\": dt_predictions[:, 1]})\n",
    "\n",
    "# Save submission files to CSV\n",
    "submission_dt.to_csv(\"submission_dt_with_imputation_and_feature_selection.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Wasi Khan\\anaconda3\\envs\\iml\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Feature  Importance\n",
      "1                     ethnicity_2    0.001343\n",
      "54              gcs_verbal_apache    0.000924\n",
      "19                     icu_type_5    0.000619\n",
      "59              ventilated_apache    0.000464\n",
      "23         apache_3j_bodysystem_2    0.000060\n",
      "..                            ...         ...\n",
      "87               d1_potassium_max         NaN\n",
      "88  apache_4a_hospital_death_prob         NaN\n",
      "89       apache_4a_icu_death_prob         NaN\n",
      "90              immunosuppression         NaN\n",
      "91    solid_tumor_with_metastasis         NaN\n",
      "\n",
      "[92 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Load training and test data\n",
    "train_data = pd.read_csv(\"D:/IBA/ML/Competition/train.csv\")  # Replace \"train.csv\" with your training file path\n",
    "test_data = pd.read_csv(\"D:/IBA/ML/Competition/test.csv\")    # Replace \"test.csv\" with your test file path\n",
    "\n",
    "# Data preprocessing\n",
    "# For simplicity, we'll encode categorical features using LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "categorical_features = [\"ethnicity\", \"gender\", \"icu_admit_source\", \"icu_stay_type\", \"icu_type\", \"apache_3j_bodysystem\", \"apache_2_bodysystem\"]\n",
    "for feature in categorical_features:\n",
    "    train_data[feature] = label_encoder.fit_transform(train_data[feature])\n",
    "    test_data[feature] = label_encoder.transform(test_data[feature])\n",
    "\n",
    "# One-hot encoding for categorical features\n",
    "encoder = OneHotEncoder(drop='first', sparse=False)\n",
    "X_categorical = encoder.fit_transform(train_data[categorical_features])\n",
    "test_data_categorical = encoder.transform(test_data[categorical_features])\n",
    "\n",
    "# Create DataFrame with column names for one-hot encoded features\n",
    "encoded_feature_names = encoder.get_feature_names_out(input_features=categorical_features)\n",
    "\n",
    "# Combine one-hot encoded categorical and non-categorical features\n",
    "X = pd.concat([pd.DataFrame(X_categorical, columns=encoded_feature_names), train_data.drop(columns=[\"RecordID\", \"hospital_death\"] + categorical_features)], axis=1)\n",
    "test_data_processed = pd.concat([pd.DataFrame(test_data_categorical, columns=encoded_feature_names), test_data.drop(columns=[\"RecordID\"] + categorical_features)], axis=1)\n",
    "\n",
    "# Split the training data into features and target variable\n",
    "y = train_data[\"hospital_death\"]\n",
    "\n",
    "# Train and make predictions using Decision Tree\n",
    "dt_model = DecisionTreeClassifier()\n",
    "dt_model.fit(X, y)\n",
    "\n",
    "# Get feature importances\n",
    "importances = dt_model.feature_importances_\n",
    "\n",
    "# Create a DataFrame to store feature names and their importances\n",
    "feature_importance_df = pd.DataFrame({\"Feature\": X.columns, \"Importance\": importances})\n",
    "\n",
    "# Sort features by importance (descending order)\n",
    "feature_importance_df = feature_importance_df.sort_values(by=\"Importance\", ascending=False)\n",
    "\n",
    "# Print or save the feature importance DataFrame as needed\n",
    "print(feature_importance_df)\n",
    "\n",
    "# Make predictions using the trained model\n",
    "dt_predictions = dt_model.predict_proba(test_data_processed)\n",
    "\n",
    "# Create submission DataFrames\n",
    "submission_dt = pd.DataFrame({\"RecordID\": test_data[\"RecordID\"], \"hospital_death\": dt_predictions[:, 1]})\n",
    "\n",
    "# Save submission files to CSV\n",
    "submission_dt.to_csv(\"submission_dt3 - 14.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
