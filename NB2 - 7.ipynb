{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['hospital_death'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32md:\\IBA\\ML\\Competition\\NB2 - 7.ipynb Cell 1\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/IBA/ML/Competition/NB2%20-%207.ipynb#W0sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m encoder \u001b[39m=\u001b[39m OneHotEncoder(drop\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mfirst\u001b[39m\u001b[39m'\u001b[39m, sparse\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/IBA/ML/Competition/NB2%20-%207.ipynb#W0sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m \u001b[39m# Fit the encoder on the categorical columns from both training and test data\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/IBA/ML/Competition/NB2%20-%207.ipynb#W0sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m encoder\u001b[39m.\u001b[39mfit(pd\u001b[39m.\u001b[39mconcat([train_data_imputed[categorical_columns], test_data_imputed[categorical_columns]]))\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/IBA/ML/Competition/NB2%20-%207.ipynb#W0sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m \u001b[39m# Transform the categorical columns for both training and test data\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/IBA/ML/Competition/NB2%20-%207.ipynb#W0sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m X_train_encoded \u001b[39m=\u001b[39m encoder\u001b[39m.\u001b[39mtransform(train_data_imputed[categorical_columns])\n",
      "File \u001b[1;32mc:\\Users\\Wasi Khan\\anaconda3\\envs\\iml\\lib\\site-packages\\pandas\\core\\frame.py:3902\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3900\u001b[0m     \u001b[39mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   3901\u001b[0m         key \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(key)\n\u001b[1;32m-> 3902\u001b[0m     indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49m_get_indexer_strict(key, \u001b[39m\"\u001b[39;49m\u001b[39mcolumns\u001b[39;49m\u001b[39m\"\u001b[39;49m)[\u001b[39m1\u001b[39m]\n\u001b[0;32m   3904\u001b[0m \u001b[39m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   3905\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(indexer, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39m==\u001b[39m \u001b[39mbool\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\Wasi Khan\\anaconda3\\envs\\iml\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6114\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6111\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   6112\u001b[0m     keyarr, indexer, new_indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 6114\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[0;32m   6116\u001b[0m keyarr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtake(indexer)\n\u001b[0;32m   6117\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, Index):\n\u001b[0;32m   6118\u001b[0m     \u001b[39m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Wasi Khan\\anaconda3\\envs\\iml\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6178\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   6175\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNone of [\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m] are in the [\u001b[39m\u001b[39m{\u001b[39;00maxis_name\u001b[39m}\u001b[39;00m\u001b[39m]\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   6177\u001b[0m not_found \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[39m.\u001b[39mnonzero()[\u001b[39m0\u001b[39m]]\u001b[39m.\u001b[39munique())\n\u001b[1;32m-> 6178\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mnot_found\u001b[39m}\u001b[39;00m\u001b[39m not in index\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['hospital_death'] not in index\""
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "# Define paths to your train and test data\n",
    "train_path = \"D:/IBA/ML/Competition/train.csv\"\n",
    "test_path = \"D:/IBA/ML/Competition/test.csv\"\n",
    "\n",
    "# Load the data\n",
    "train_data = pd.read_csv(train_path)\n",
    "test_data = pd.read_csv(test_path)\n",
    "\n",
    "# Separate numerical and categorical columns\n",
    "numerical_columns = train_data.select_dtypes(include=np.number).columns.tolist()\n",
    "numerical_columns.remove('hospital_death')\n",
    "categorical_columns = train_data.columns.difference(numerical_columns).tolist()\n",
    "target_column = 'hospital_death'\n",
    "\n",
    "# Handle missing values using KNN imputation for numerical columns\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "imputer.fit(train_data[numerical_columns])  # Fit the imputer on the numerical columns\n",
    "train_data_imputed = train_data.copy()\n",
    "test_data_imputed = test_data.copy()\n",
    "train_data_imputed[numerical_columns] = imputer.transform(train_data[numerical_columns])\n",
    "test_data_imputed[numerical_columns] = imputer.transform(test_data[numerical_columns])\n",
    "\n",
    "# Perform one-hot encoding for categorical features AFTER imputation\n",
    "encoder = OneHotEncoder(drop='first', sparse=False)\n",
    "\n",
    "# Fit the encoder on the categorical columns from both training and test data\n",
    "encoder.fit(pd.concat([train_data_imputed[categorical_columns], test_data_imputed[categorical_columns]]))\n",
    "\n",
    "# Transform the categorical columns for both training and test data\n",
    "X_train_encoded = encoder.transform(train_data_imputed[categorical_columns])\n",
    "X_test_encoded = encoder.transform(test_data_imputed[categorical_columns])\n",
    "\n",
    "# Combine the encoded categorical features with the numerical features\n",
    "X_train = np.hstack((X_train_encoded, train_data_imputed[numerical_columns]))\n",
    "X_test = np.hstack((X_test_encoded, test_data_imputed[numerical_columns]))\n",
    "y_train = train_data[target_column]\n",
    "\n",
    "# Use SelectKBest to perform feature selection\n",
    "k_best = SelectKBest(score_func=f_classif, k=15)  # You can adjust the number of features (k) as needed\n",
    "X_train_selected = k_best.fit_transform(X_train, y_train)\n",
    "X_test_selected = k_best.transform(X_test)\n",
    "\n",
    "# Split the data for model training and validation\n",
    "X_train_final, X_val, y_train_final, y_val = train_test_split(X_train_selected, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a Gaussian Naive Bayes classifier with hyperparameter tuning\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train_final, y_train_final)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_val_pred = gnb.predict_proba(X_val)[:, 1]\n",
    "\n",
    "# Calculate ROC AUC score for validation\n",
    "roc_auc = roc_auc_score(y_val, y_val_pred)\n",
    "print(f'Validation ROC AUC: {roc_auc:.4f}')\n",
    "\n",
    "# Make predictions on the test data\n",
    "test_predictions = gnb.predict_proba(X_test_selected)[:, 1]\n",
    "\n",
    "# Create a submission file in the required format\n",
    "submission_df = pd.DataFrame({'RecordID': test_data['RecordID'], 'hospital_death': test_predictions})\n",
    "\n",
    "# Save the submission file\n",
    "submission_path = \"D:/IBA/ML/Competition/submission_nb_with_feature_selection.csv\"\n",
    "submission_df.to_csv(submission_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Wasi Khan\\anaconda3\\envs\\iml\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "\n",
    "# Load training and test data\n",
    "train_data = pd.read_csv(\"D:/IBA/ML/Competition/train.csv\")  # Replace \"train.csv\" with your training file path\n",
    "test_data = pd.read_csv(\"D:/IBA/ML/Competition/test.csv\")    # Replace \"test.csv\" with your test file path\n",
    "\n",
    "# Data preprocessing\n",
    "# One-hot encoding for categorical features\n",
    "encoder = OneHotEncoder(drop='first', sparse=False)\n",
    "categorical_features = [\"ethnicity\", \"gender\", \"icu_admit_source\", \"icu_stay_type\", \"icu_type\", \"apache_3j_bodysystem\", \"apache_2_bodysystem\"]\n",
    "X_categorical = encoder.fit_transform(train_data[categorical_features])\n",
    "test_data_categorical = encoder.transform(test_data[categorical_features])\n",
    "\n",
    "# KNN impute missing values in both training and test data\n",
    "knn_imputer = KNNImputer(n_neighbors=7)\n",
    "numerical_features = [col for col in train_data.columns if col not in [\"RecordID\", \"hospital_death\"] + categorical_features]\n",
    "X_numerical = train_data[numerical_features].values\n",
    "test_data_numerical = test_data[numerical_features].values\n",
    "X_numerical_imputed = knn_imputer.fit_transform(X_numerical)\n",
    "test_data_numerical_imputed = knn_imputer.transform(test_data_numerical)\n",
    "\n",
    "# Create feature names for one-hot encoded columns\n",
    "encoded_feature_names = encoder.get_feature_names_out(categorical_features)\n",
    "\n",
    "# Combine one-hot encoded categorical and KNN imputed numerical features\n",
    "X = pd.DataFrame(X_categorical, columns=encoded_feature_names)\n",
    "X[numerical_features] = pd.DataFrame(X_numerical_imputed, columns=numerical_features)\n",
    "\n",
    "test_data_processed = pd.DataFrame(test_data_categorical, columns=encoded_feature_names)\n",
    "test_data_processed[numerical_features] = pd.DataFrame(test_data_numerical_imputed, columns=numerical_features)\n",
    "\n",
    "# Apply Min-Max scaling to ensure non-negative values\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "test_data_scaled = scaler.transform(test_data_processed)\n",
    "\n",
    "# Select the top 10 features based on statistical significance (chi-squared)\n",
    "selector = SelectKBest(chi2, k=10)\n",
    "X_selected = selector.fit_transform(X_scaled, train_data[\"hospital_death\"])\n",
    "test_data_selected = selector.transform(test_data_scaled)\n",
    "\n",
    "# Target variable\n",
    "y = train_data[\"hospital_death\"]\n",
    "\n",
    "# Train Naive Bayes on the selected features\n",
    "nb_model = GaussianNB()\n",
    "nb_model.fit(X_selected, y)\n",
    "\n",
    "# Make predictions using the trained model\n",
    "nb_predictions = nb_model.predict_proba(test_data_selected)\n",
    "\n",
    "# Create submission DataFrames\n",
    "submission_nb = pd.DataFrame({\"RecordID\": test_data[\"RecordID\"], \"hospital_death\": nb_predictions[:, 1]})\n",
    "\n",
    "# Save submission files to CSV\n",
    "submission_nb.to_csv(\"submission_nb2 - 13.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
